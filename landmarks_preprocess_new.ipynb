{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "677b449b-58bf-49c3-9139-d4240f8a45e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dlib\n",
    "import os\n",
    "import shutil\n",
    "import cv2\n",
    "import json\n",
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4aea2058-b3e6-4c7d-a02a-e84117c6977b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LandmarksDataset_original:\n",
    "    def __init__(self, root_dir):\n",
    "        self.root_dir = root_dir\n",
    "        self.image_files = [f for f in os.listdir(root_dir) if f.endswith('.jpg')]\n",
    "        self.landmarks_files = [f for f in os.listdir(root_dir) if f.endswith('.pts')]\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir, self.image_files[idx])\n",
    "        image = cv2.imread(img_name)\n",
    "\n",
    "        landmarks_name = os.path.join(self.root_dir, self.landmarks_files[idx])\n",
    "        landmarks = self._load_landmarks(landmarks_name)\n",
    "\n",
    "        return image, landmarks\n",
    "\n",
    "    def _load_landmarks(self, file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            landmarks = []\n",
    "            for line in f.readlines()[3:-1]:  # skip the first 3 and last lines\n",
    "                x, y = map(float, line.split())\n",
    "                landmarks.append([x, y])\n",
    "            return np.array(landmarks)\n",
    "\n",
    "def get_landmarks_bbox(landmarks):\n",
    "    x_min = np.min(landmarks[:, 0])\n",
    "    x_max = np.max(landmarks[:, 0])\n",
    "    y_min = np.min(landmarks[:, 1])\n",
    "    y_max = np.max(landmarks[:, 1])\n",
    "    return dlib.rectangle(left=int(x_min), top=int(y_min), right=int(x_max), bottom=int(y_max))\n",
    "\n",
    "def calculate_iou(bbox1, bbox2):\n",
    "    # Calculate intersection area\n",
    "    inter_left = max(bbox1.left(), bbox2.left())\n",
    "    inter_top = max(bbox1.top(), bbox2.top())\n",
    "    inter_right = min(bbox1.right(), bbox2.right())\n",
    "    inter_bottom = min(bbox1.bottom(), bbox2.bottom())\n",
    "    inter_area = max(0, inter_right - inter_left + 1) * max(0, inter_bottom - inter_top + 1)\n",
    "\n",
    "    # Calculate union area\n",
    "    bbox1_area = (bbox1.right() - bbox1.left() + 1) * (bbox1.bottom() - bbox1.top() + 1)\n",
    "    bbox2_area = (bbox2.right() - bbox2.left() + 1) * (bbox2.bottom() - bbox2.top() + 1)\n",
    "    union_area = bbox1_area + bbox2_area - inter_area\n",
    "\n",
    "    # Calculate IoU\n",
    "    iou = inter_area / union_area\n",
    "    return iou\n",
    "\n",
    "def preprocess_dataset(dataset, json_name='preprocessed_data.json'):\n",
    "    data = {}\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    for idx in tqdm(range(len(dataset))):\n",
    "        image, landmarks = dataset[idx]\n",
    "        gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "        faces = detector(gray)\n",
    "\n",
    "        if not faces:\n",
    "            continue\n",
    "\n",
    "        max_iou = 0\n",
    "        selected_bbox = None\n",
    "        landmarks_bbox = get_landmarks_bbox(landmarks)\n",
    "\n",
    "        for face in faces:\n",
    "            iou = calculate_iou(face, landmarks_bbox)\n",
    "            if iou > max_iou:\n",
    "                max_iou = iou\n",
    "                selected_bbox = face\n",
    "\n",
    "        if selected_bbox is not None:\n",
    "            image_name = dataset.image_files[idx]\n",
    "            data[image_name] = {\n",
    "                'bbox': [selected_bbox.left(), selected_bbox.top(), selected_bbox.right(), selected_bbox.bottom()],\n",
    "                'landmarks': landmarks.tolist()\n",
    "            }\n",
    "\n",
    "    with open(json_name, 'w') as json_file:\n",
    "        json.dump(data, json_file, indent=4)\n",
    "\n",
    "def merge_datasets(folder1, folder2, output_folder):\n",
    "    # Create the output folder if it doesn't exist\n",
    "    if not os.path.exists(output_folder):\n",
    "        os.makedirs(output_folder)\n",
    "\n",
    "    # Iterate over images and landmarks in the first folder\n",
    "    for file1 in os.listdir(folder1):\n",
    "        if file1.endswith('.jpg'):\n",
    "            basename = os.path.splitext(file1)[0]\n",
    "            pts_file = os.path.join(folder1, basename + '.pts')\n",
    "            if os.path.exists(pts_file) and count_landmarks(pts_file) == 68:\n",
    "                shutil.copy(os.path.join(folder1, file1), os.path.join(output_folder, file1))\n",
    "                shutil.copy(pts_file, os.path.join(output_folder, basename + '.pts'))\n",
    "\n",
    "    # Iterate over images and landmarks in the second folder\n",
    "    for file2 in os.listdir(folder2):\n",
    "        if file2.endswith('.jpg'):\n",
    "            basename = os.path.splitext(file2)[0]\n",
    "            pts_file = os.path.join(folder2, basename + '.pts')\n",
    "            if os.path.exists(pts_file) and count_landmarks(pts_file) == 68:\n",
    "                shutil.copy(os.path.join(folder2, file2), os.path.join(output_folder, file2))\n",
    "                shutil.copy(pts_file, os.path.join(output_folder, basename + '.pts'))\n",
    "\n",
    "def count_landmarks(pts_file):\n",
    "    with open(pts_file, 'r') as f:\n",
    "        num_landmarks = sum(1 for line in f.readlines()[3:-1])\n",
    "    return num_landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "56d0fd88-5fa4-4509-8013-1b48d89e6541",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0052a2453f6f4ac3b9e10f75bcd33aff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/8539 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2eba9eaa72514190a6d60cf068a6b9bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/942 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "folder1 = './landmarks_task/Menpo/train/'\n",
    "folder2 = './landmarks_task/300W/train/'\n",
    "output_folder = 'merged_landmarks_train'\n",
    "merge_datasets(folder1, folder2, output_folder)\n",
    "\n",
    "folder1 = './landmarks_task/Menpo/test/'\n",
    "folder2 = './landmarks_task/300W/test/'\n",
    "output_folder = 'merged_landmarks_test'\n",
    "merge_datasets(folder1, folder2, output_folder)\n",
    "\n",
    "dataset = LandmarksDataset_original('./merged_landmarks_train/')\n",
    "preprocess_dataset(dataset, json_name='train_data.json')\n",
    "\n",
    "dataset = LandmarksDataset_original('./merged_landmarks_test/')\n",
    "preprocess_dataset(dataset, json_name='test_data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "abb0a503-ca2a-4c4b-bbc6-253f435d969f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LandmarksDataset_from_json:\n",
    "    def __init__(self, root_dir, json_file):\n",
    "        self.root_dir = root_dir\n",
    "        with open(json_file, 'r') as f:\n",
    "            self.data = json.load(f)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = list(self.data.keys())[idx]\n",
    "        img_path = os.path.join(self.root_dir, img_name)\n",
    "        image = cv2.imread(img_path)\n",
    "        info = self.data[img_name]\n",
    "        bbox = info['bbox']\n",
    "        landmarks = np.array(info['landmarks'])\n",
    "        return image, bbox, landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0efe318c-00fc-4aa8-89ae-56521eac5460",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def visualize(image, bbox, landmarks, img_path):\n",
    "#     plt.figure(figsize=(8, 8))\n",
    "#     plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "#     plt.gca().add_patch(plt.Rectangle((bbox[0], bbox[1]), bbox[2] - bbox[0], bbox[3] - bbox[1], linewidth=2, edgecolor='g', facecolor='none'))\n",
    "#     for landmark in landmarks:\n",
    "#         plt.scatter(landmark[0], landmark[1], c='r', s=20)\n",
    "#     plt.axis('off')\n",
    "#     plt.title(f\"Image Path: {img_path}\")\n",
    "#     plt.show()\n",
    "\n",
    "# dataset = LandmarksDataset_from_json('./merged_landmarks_test/', 'test_data.json')\n",
    "# for idx in range(len(dataset)):\n",
    "#     image, bbox, landmarks = dataset[idx]\n",
    "#     img_name = list(dataset.data.keys())[idx]\n",
    "#     img_path = os.path.join('./merged_landmarks_test/', img_name)\n",
    "#     visualize(image, bbox, landmarks, img_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "582e07db-15dc-42f1-bdd5-6732d7fddedd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dlib\n",
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# def detect_and_visualize(image_path):\n",
    "#     # Load the image\n",
    "#     image = cv2.imread(image_path)\n",
    "    \n",
    "#     # Convert the image to grayscale\n",
    "#     gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    \n",
    "#     # Initialize the face detector from dlib\n",
    "#     detector = dlib.get_frontal_face_detector()\n",
    "    \n",
    "#     # Detect faces in the grayscale image\n",
    "#     faces = detector(gray)\n",
    "    \n",
    "#     # Visualize the image and detected faces\n",
    "#     plt.figure(figsize=(8, 8))\n",
    "#     plt.imshow(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
    "#     for face in faces:\n",
    "#         x, y, w, h = face.left(), face.top(), face.width(), face.height()\n",
    "#         plt.gca().add_patch(plt.Rectangle((x, y), w, h, linewidth=2, edgecolor='g', facecolor='none'))\n",
    "#     plt.axis('off')\n",
    "#     plt.title('Detected Faces')\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9cffa1fe-ed06-4a1f-9ff7-c431849148fe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# error_image_path = './merged_landmarks_test/aflw__face_64689.jpg'\n",
    "# detect_and_visualize(error_image_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70c2f0b-5f51-4e47-b1ae-e1c15f152a23",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
